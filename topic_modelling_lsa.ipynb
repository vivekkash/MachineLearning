{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter search query chandrayaan\n",
      "http://www.google.com/search?q=chandrayaan\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "query = input(\"Enter search query \")\n",
    "query = query.replace(\" \",\"+\")\n",
    "url = \"http://www.google.com/search?q=\"+str(query)\n",
    "print (url)\n",
    "req = urllib.request.Request(url, headers={'User-Agent' : \"Magic Browser\"})\n",
    "response = urllib.request.urlopen( req )\n",
    "html = response.read()\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/Arunabh/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "all_links=[]\n",
    "for link in soup.findAll('a'):\n",
    "    all_links.append(link.get('href'))\n",
    "    \n",
    "imp_links = []\n",
    "for x in all_links:\n",
    "    if x.startswith(\"/url\"):\n",
    "        imp_links.append(x)\n",
    "        \n",
    "        \n",
    "final_links = []\n",
    "for x in imp_links:\n",
    "    final_links.append(\"https://google.com\"+x)\n",
    "\n",
    "    \n",
    "text=[]\n",
    "for i in range(len(final_links)):\n",
    "    req = urllib.request.Request(final_links[i],headers = {'User-Agent' : 'Magic Browser'})\n",
    "    response = urllib.request.urlopen(req)\n",
    "    html = response.read()\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    for j in range(len(soup.find_all('p'))):\n",
    "        text.append(soup.find_all('p')[j].get_text())\n",
    "\n",
    "        \n",
    "#NLTK for cleaning\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "stuff_to_be_removed = list(stopwords.words(\"english\"))+list(punctuation)\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "def my_tokenizer(s):\n",
    "    s = s.lower()\n",
    "    text = nltk.tokenize.word_tokenize(s)\n",
    "    text = [t for t in text if len(t) > 2]\n",
    "    text = [lemmatizer.lemmatize(y) for y in text if y not in stuff_to_be_removed]\n",
    "    text = [t for t in text if not any(c.isdigit() for c in t)]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "final_text = [my_tokenizer(s) for s in text]\n",
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "df[\"text\"] = final_text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "vector = tfidf.fit_transform(df[\"text\"])\n",
    "X = vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "lsa = TruncatedSVD(n_components=10, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=10, n_iter=100,\n",
       "             random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lsa.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranking_topic_8 = lsa.components_[7].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = dict(zip(words,ranking_topic_8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = pd.DataFrame(list(d.items()), columns=[\"words\", \"ranking\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d.sort_values([\"ranking\"], ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 0 ;\n",
      "('lunar', 0.2754018597222927)\n",
      "('orbit', 0.25367574278087124)\n",
      "('moon', 0.25042511271278917)\n",
      "('mission', 0.20376560270784969)\n",
      "('spacecraft', 0.18566065058466558)\n",
      "('isro', 0.17507702300115222)\n",
      "('surface', 0.16750792895118627)\n",
      "('space', 0.14976885203293208)\n",
      "('launch', 0.13429571409077712)\n",
      "('indian', 0.12630880001001388)\n",
      "\n",
      "Topic 1 ;\n",
      "('orbit', 0.36780065325325306)\n",
      "('spacecraft', 0.24490913030790412)\n",
      "('manoeuvre', 0.20612086178187422)\n",
      "('minute', 0.19291099594590638)\n",
      "('took', 0.19217340358212429)\n",
      "('engine', 0.18488824761708864)\n",
      "('raising', 0.179886004681796)\n",
      "('fired', 0.17129620769867887)\n",
      "('utc', 0.1643551435977019)\n",
      "('half', 0.1597557022706967)\n",
      "\n",
      "Topic 2 ;\n",
      "('advertisement', 1.0)\n",
      "('launch', 1.3015078961964956e-15)\n",
      "('satellite', 1.2449710568688095e-15)\n",
      "('orbit', 1.1831487590290802e-15)\n",
      "('displayed', 8.672356732895626e-16)\n",
      "('vehicle', 8.037853979210593e-16)\n",
      "('gslv', 6.826786876673898e-16)\n",
      "('spacecraft', 6.418171071172997e-16)\n",
      "('india', 5.436858640311033e-16)\n",
      "('space', 5.426052814688503e-16)\n",
      "\n",
      "Topic 3 ;\n",
      "('launch', 0.2666505206478122)\n",
      "('satellite', 0.2304355892168255)\n",
      "('space', 0.2078107454373419)\n",
      "('india', 0.1858061223751099)\n",
      "('indian', 0.16499153491203902)\n",
      "('mission', 0.16372366785797807)\n",
      "('isro', 0.15564105352373883)\n",
      "('vehicle', 0.15174553059226717)\n",
      "('gslv', 0.1430652765412349)\n",
      "('launched', 0.12525031016673832)\n",
      "\n",
      "Topic 4 ;\n",
      "('displayed', 0.9999999999999994)\n",
      "('mission', 1.7215252660678379e-15)\n",
      "('lander', 1.2634161759378223e-15)\n",
      "('vikram', 8.652406062367199e-16)\n",
      "('instrument', 7.785649659115372e-16)\n",
      "('orbiter', 7.328935357667598e-16)\n",
      "('scientific', 6.615864266398405e-16)\n",
      "('landing', 6.139633470969555e-16)\n",
      "('rover', 6.133616277726189e-16)\n",
      "('objective', 5.757880931021349e-16)\n",
      "\n",
      "Topic 5 ;\n",
      "('image', 0.4516321305605984)\n",
      "('captured', 0.22243764213744388)\n",
      "('mapping', 0.18257887576098053)\n",
      "('terrain', 0.17002348156206085)\n",
      "('view', 0.1682467708491833)\n",
      "('dimensional', 0.15127283205859549)\n",
      "('isro', 0.14776887592701937)\n",
      "('new', 0.12952850072332914)\n",
      "('three', 0.12197971145763459)\n",
      "('aboard', 0.11778151383097382)\n",
      "\n",
      "Topic 6 ;\n",
      "('right', 0.5140411237652706)\n",
      "('service', 0.3966908505495968)\n",
      "('copyright', 0.30204210167911805)\n",
      "('reserved', 0.27947256548352983)\n",
      "('reprint', 0.24873202720780568)\n",
      "('syndication', 0.24873202720780568)\n",
      "('ltd', 0.22332498651977442)\n",
      "('bennett', 0.21586229462465692)\n",
      "('coleman', 0.21586229462465692)\n",
      "('co', 0.21090564377183044)\n",
      "\n",
      "Topic 7 ;\n",
      "('satellite', 0.3174692838826794)\n",
      "('launch', 0.27874896806977484)\n",
      "('gslv', 0.19843995073847123)\n",
      "('vehicle', 0.18072609894389427)\n",
      "('iii', 0.15999681445206176)\n",
      "('water', 0.15121729564017816)\n",
      "('stage', 0.09543446318265453)\n",
      "('launched', 0.09126060353402546)\n",
      "('ice', 0.09070208778190297)\n",
      "('crater', 0.08708590179011667)\n",
      "\n",
      "Topic 8 ;\n",
      "('space', 0.28367720282443926)\n",
      "('indian', 0.278963865067576)\n",
      "('research', 0.19189758092964493)\n",
      "('india', 0.17610390116340058)\n",
      "('organisation', 0.1598733437680259)\n",
      "('moon', 0.14095788854729832)\n",
      "('released', 0.10443504656423434)\n",
      "('science', 0.09931167958676664)\n",
      "('network', 0.0878178162135798)\n",
      "('wednesday', 0.08688810745370346)\n",
      "\n",
      "Topic 9 ;\n",
      "('lunar', 0.2959942951733489)\n",
      "('view', 0.19343453229396274)\n",
      "('india', 0.13138939097135238)\n",
      "('complete', 0.12327256208117605)\n",
      "('network', 0.11525549693770687)\n",
      "('imaged', 0.11079993686892932)\n",
      "('look', 0.10145780917903037)\n",
      "('sar', 0.10072395559803066)\n",
      "('spatial', 0.10053497981516181)\n",
      "('mini', 0.09836087272608847)\n"
     ]
    }
   ],
   "source": [
    "words = tfidf.get_feature_names()\n",
    "for i,y in enumerate(lsa.components_):\n",
    "    componentwords = zip(words, y)\n",
    "    sortedComponentwords = sorted(componentwords, key = lambda x: x[1],\n",
    "                                reverse=True)\n",
    "    sortedComponentwords = sortedComponentwords[:10]\n",
    "    print (\"\\nTopic\", i, \";\")\n",
    "    for x in sortedComponentwords:\n",
    "        print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
