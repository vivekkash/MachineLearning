{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyper paramter tuning in Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPgLs8+Utw9N0Em6Umc2jC1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivekkash/MachineLearning/blob/master/Hyper_paramter_tuning_in_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gWUP-gtVlUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Day2 : hyper parameter optimization - Regularization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YoprfWzV1lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "#from keras.models import Sequential\n",
        "#from keras.layers.core import Dense, Dropout, Activation\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# load the data\n",
        "dataset = pd.read_csv('https://raw.githubusercontent.com/bhushan45/churn_modeling/master/Churn_Modelling.csv')\n",
        "\n",
        "X = dataset.iloc[:,3:13].values\n",
        "y = dataset.iloc[:, 13].values\n",
        "\n",
        "labelencoder_X_1 = LabelEncoder() #creating label encoder to region name\n",
        "X[:, 1] = labelencoder_X_1.fit_transform(X[:,1]) #encoding region from string to just 3 no. 0,1,2 resp.\n",
        "labelencoder_X_2 = LabelEncoder() #creating label encoder to g4ender name\n",
        "X[:, 2] = labelencoder_X_2.fit_transform(X[:,2]) #encoding region from string to just 3 no. 0,1 (male, famale) resp.\n",
        "\n",
        "onehotencoder = OneHotEncoder()\n",
        "\n",
        "X_1 = onehotencoder.fit_transform(np.reshape(X[:,1],(-1,1))).toarray()\n",
        "\n",
        "X = np.hstack((X[: ,:1],X_1,X[:,2:]))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)â€©\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsBp6C_BWU6p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13b5ba37-4c9b-4ea8-d2d7-2eb760550e59"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hk0QToPZsLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dropout,Activation,Dense\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pyRBW2WaMTp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "160342b2-919f-4cd3-e309-681e53aa9930"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(10,input_shape=(X_train.shape[1],),activation='relu'))\n",
        "model.add(Dense(20,activation='relu'))\n",
        "model.add(Dense(5,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train,y_train,validation_split=0.2 ,epochs=40,batch_size=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "64/64 [==============================] - 0s 4ms/step - loss: 0.6003 - accuracy: 0.7402 - val_loss: 0.5394 - val_accuracy: 0.7975\n",
            "Epoch 2/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7966 - val_loss: 0.4892 - val_accuracy: 0.7975\n",
            "Epoch 3/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8002 - val_loss: 0.4609 - val_accuracy: 0.8012\n",
            "Epoch 4/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8083 - val_loss: 0.4413 - val_accuracy: 0.8069\n",
            "Epoch 5/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8181 - val_loss: 0.4296 - val_accuracy: 0.8156\n",
            "Epoch 6/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8241 - val_loss: 0.4200 - val_accuracy: 0.8281\n",
            "Epoch 7/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8291 - val_loss: 0.4126 - val_accuracy: 0.8319\n",
            "Epoch 8/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8350 - val_loss: 0.4059 - val_accuracy: 0.8350\n",
            "Epoch 9/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8403 - val_loss: 0.3980 - val_accuracy: 0.8331\n",
            "Epoch 10/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8462 - val_loss: 0.3903 - val_accuracy: 0.8394\n",
            "Epoch 11/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8483 - val_loss: 0.3855 - val_accuracy: 0.8388\n",
            "Epoch 12/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8530 - val_loss: 0.3809 - val_accuracy: 0.8419\n",
            "Epoch 13/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8528 - val_loss: 0.3786 - val_accuracy: 0.8456\n",
            "Epoch 14/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8545 - val_loss: 0.3728 - val_accuracy: 0.8500\n",
            "Epoch 15/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8547 - val_loss: 0.3713 - val_accuracy: 0.8500\n",
            "Epoch 16/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8541 - val_loss: 0.3703 - val_accuracy: 0.8500\n",
            "Epoch 17/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8556 - val_loss: 0.3691 - val_accuracy: 0.8531\n",
            "Epoch 18/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8553 - val_loss: 0.3681 - val_accuracy: 0.8512\n",
            "Epoch 19/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3472 - accuracy: 0.8564 - val_loss: 0.3670 - val_accuracy: 0.8525\n",
            "Epoch 20/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8566 - val_loss: 0.3689 - val_accuracy: 0.8512\n",
            "Epoch 21/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8569 - val_loss: 0.3667 - val_accuracy: 0.8550\n",
            "Epoch 22/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8553 - val_loss: 0.3663 - val_accuracy: 0.8537\n",
            "Epoch 23/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8581 - val_loss: 0.3643 - val_accuracy: 0.8531\n",
            "Epoch 24/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8603 - val_loss: 0.3648 - val_accuracy: 0.8525\n",
            "Epoch 25/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8584 - val_loss: 0.3630 - val_accuracy: 0.8500\n",
            "Epoch 26/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8597 - val_loss: 0.3632 - val_accuracy: 0.8512\n",
            "Epoch 27/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8584 - val_loss: 0.3614 - val_accuracy: 0.8525\n",
            "Epoch 28/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8602 - val_loss: 0.3607 - val_accuracy: 0.8525\n",
            "Epoch 29/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8595 - val_loss: 0.3629 - val_accuracy: 0.8544\n",
            "Epoch 30/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8623 - val_loss: 0.3596 - val_accuracy: 0.8544\n",
            "Epoch 31/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8620 - val_loss: 0.3595 - val_accuracy: 0.8575\n",
            "Epoch 32/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8608 - val_loss: 0.3615 - val_accuracy: 0.8562\n",
            "Epoch 33/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8641 - val_loss: 0.3575 - val_accuracy: 0.8562\n",
            "Epoch 34/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8595 - val_loss: 0.3572 - val_accuracy: 0.8569\n",
            "Epoch 35/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8625 - val_loss: 0.3593 - val_accuracy: 0.8556\n",
            "Epoch 36/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8625 - val_loss: 0.3567 - val_accuracy: 0.8550\n",
            "Epoch 37/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8631 - val_loss: 0.3563 - val_accuracy: 0.8606\n",
            "Epoch 38/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8623 - val_loss: 0.3561 - val_accuracy: 0.8550\n",
            "Epoch 39/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8644 - val_loss: 0.3557 - val_accuracy: 0.8569\n",
            "Epoch 40/40\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8658 - val_loss: 0.3566 - val_accuracy: 0.8531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb786365860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfTXTldEaRoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred_c = np.where(y_pred > 0.5, 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKWV-uGIa2V8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44efe581-bf40-438c-eb67-20eb809469aa"
      },
      "source": [
        "print('Accuracy for Keras {}'.format(accuracy_score(y_pred_c,y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for Keras 0.8575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLTzJn7Ta5W8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dropout Regularization in Keras\n",
        "# Incase of overfitting of model do dropouts \n",
        "# In keras = 20% dropout means  20% conn are dropped\n",
        "# Im tensorflow = 80% mean 80% conn are retained"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NOXihoLcKww",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b2cff1be-2566-4236-f59b-2612e2d240fe"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers\n",
        "from keras.layers import Dropout\n",
        "from keras import regularizers\n",
        "\n",
        "classifier = Sequential()\n",
        "classifier.add(Dense(activation='relu', input_dim=12,units=6, kernel_initializer=\"uniform\"))\n",
        "classifier.add(Dense(activation='relu', units=6, kernel_initializer=\"uniform\"))\n",
        "classifier.add(Dense(activation='sigmoid', units=1, kernel_initializer=\"uniform\"))\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.005, decay=1e-6, momentum=0, nesterov=False)\n",
        "classifier.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "classifier.fit(X_train,y_train,verbose=0,epochs=50,batch_size=20)\n",
        "score = classifier.evaluate(X_test,y_test)\n",
        "print(\"Score: \")\n",
        "print(score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 912us/step - loss: 0.5012 - accuracy: 0.7975\n",
            "Score: \n",
            "0.7975000143051147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOi3GmX_lbuH",
        "colab_type": "text"
      },
      "source": [
        "## Adding dropout in visible layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSaL8PDRlf2H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "828ac90a-5e80-4460-82af-62a27f7f56d0"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers\n",
        "from keras.layers import Dropout\n",
        "from keras import regularizers\n",
        "\n",
        "classifier = Sequential()\n",
        "classifier.add(Dropout(0.2, input_shape=(12,))) # dropout 20% on the visible layer that is below layer\n",
        "classifier.add(Dense(activation='relu', input_dim=12,units=6, kernel_initializer=\"uniform\"))\n",
        "classifier.add(Dense(activation='relu', units=6, kernel_initializer=\"uniform\"))\n",
        "classifier.add(Dense(activation='sigmoid', units=1, kernel_initializer=\"uniform\"))\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.005, decay=1e-6, momentum=0, nesterov=False)\n",
        "classifier.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "classifier.fit(X_train,y_train,verbose=0,epochs=50,batch_size=20)\n",
        "score = classifier.evaluate(X_test,y_test)\n",
        "print(\"Score: \")\n",
        "print(score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 1ms/step - loss: 0.5037 - accuracy: 0.7975\n",
            "Score: \n",
            "0.7975000143051147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34Unqn_xlwpA",
        "colab_type": "text"
      },
      "source": [
        "## Adding dropout in consecutive layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMjgYaL0l235",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d969df28-f820-4b47-cfc1-019c781e15f1"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers\n",
        "from keras.layers import Dropout\n",
        "from keras import regularizers\n",
        "\n",
        "classifier = Sequential()\n",
        "classifier.add(Dropout(0.2, input_shape=(12,))) # dropout 20% on the visible layer that is below layer\n",
        "classifier.add(Dense(activation='relu', input_dim=12,units=6, kernel_initializer=\"uniform\"))\n",
        "classifier.add(Dropout(0.2)) # dropout 20% on the hidden layer that is below layer\n",
        "classifier.add(Dense(activation='relu', units=6, kernel_initializer=\"uniform\"))\n",
        "classifier.add(Dropout(0.2)) # dropout 20% on the hidden layer that is below layer\n",
        "classifier.add(Dense(activation='sigmoid', units=1, kernel_initializer=\"uniform\"))\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.005, decay=1e-6, momentum=0, nesterov=False)\n",
        "classifier.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "classifier.fit(X_train,y_train,verbose=0,epochs=50,batch_size=20)\n",
        "score = classifier.evaluate(X_test,y_test)\n",
        "print(\"Score: \")\n",
        "print(score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 942us/step - loss: 0.5025 - accuracy: 0.7975\n",
            "Score: \n",
            "0.7975000143051147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "789cIFyOoc3A",
        "colab_type": "text"
      },
      "source": [
        "## Early stopping in Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFrMyVGbolqD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "178ac8bc-af86-4778-bd39-a6d6d954c643"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers\n",
        "from keras.layers import Dropout\n",
        "from keras import regularizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "#definition of earlystopping keras callback\n",
        "earlystopping = EarlyStopping(monitor='val_loss', patience=10, min_delta=0.0001)\n",
        "\n",
        "classifier = Sequential()\n",
        "#classifier.add(Dropout(0.2, input_shape=(12,))) # dropout 20% on the visible layer that is below layer\n",
        "classifier.add(Dense(activation='relu', input_dim=12,units=40, kernel_initializer=\"uniform\"))\n",
        "classifier.add(Dense(activation='relu', units=40, kernel_initializer=\"uniform\"))\n",
        "classifier.add(Dense(activation='relu', units=30, kernel_initializer=\"uniform\"))\n",
        "classifier.add(Dense(activation='relu', units=30, kernel_initializer=\"uniform\"))\n",
        "classifier.add(Dense(activation='relu', units=20, kernel_initializer=\"uniform\"))\n",
        "\n",
        "classifier.add(Dense(activation='sigmoid', units=1, kernel_initializer=\"uniform\"))\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.005, decay=1e-6, momentum=0, nesterov=False)\n",
        "classifier.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "classifier.fit(X_train,y_train,verbose=1,validation_split=0.2, epochs=50,batch_size=20,callbacks=[earlystopping])\n",
        "score = classifier.evaluate(X_test,y_test)\n",
        "print(\"Score: \")\n",
        "print(score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6380 - accuracy: 0.7958 - val_loss: 0.5952 - val_accuracy: 0.7969\n",
            "Epoch 2/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.7958 - val_loss: 0.5501 - val_accuracy: 0.7969\n",
            "Epoch 3/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5388 - accuracy: 0.7958 - val_loss: 0.5282 - val_accuracy: 0.7969\n",
            "Epoch 4/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.7958 - val_loss: 0.5172 - val_accuracy: 0.7969\n",
            "Epoch 5/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5153 - accuracy: 0.7958 - val_loss: 0.5115 - val_accuracy: 0.7969\n",
            "Epoch 6/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7958 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 7/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7958 - val_loss: 0.5069 - val_accuracy: 0.7969\n",
            "Epoch 8/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5077 - accuracy: 0.7958 - val_loss: 0.5059 - val_accuracy: 0.7969\n",
            "Epoch 9/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5070 - accuracy: 0.7958 - val_loss: 0.5054 - val_accuracy: 0.7969\n",
            "Epoch 10/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7958 - val_loss: 0.5051 - val_accuracy: 0.7969\n",
            "Epoch 11/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.7958 - val_loss: 0.5050 - val_accuracy: 0.7969\n",
            "Epoch 12/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7958 - val_loss: 0.5049 - val_accuracy: 0.7969\n",
            "Epoch 13/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7958 - val_loss: 0.5048 - val_accuracy: 0.7969\n",
            "Epoch 14/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7958 - val_loss: 0.5048 - val_accuracy: 0.7969\n",
            "Epoch 15/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 16/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 17/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 18/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 19/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 20/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 21/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 22/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 23/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.7975\n",
            "Score: \n",
            "0.7975000143051147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9glcCJIl2_MX",
        "colab_type": "text"
      },
      "source": [
        "## L1 and L2 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MTM3Tg73CkD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fcd18f2d-1b36-4b5f-eecb-095de2f92e9b"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers\n",
        "from keras.layers import Dropout\n",
        "from keras import regularizers\n",
        "\n",
        "classifier = Sequential()\n",
        "classifier.add(Dense(kernel_regularizer=regularizers.L1(0.01),activation='relu', input_dim=12,units=6, kernel_initializer=\"uniform\"))\n",
        "classifier.add(Dense(kernel_regularizer=regularizers.L1(0.01),activation='relu', units=6, kernel_initializer=\"uniform\"))\n",
        "classifier.add(Dense(kernel_regularizer=regularizers.L1(0.01),activation='sigmoid', units=1, kernel_initializer=\"uniform\"))\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.005, decay=1e-6, momentum=0, nesterov=False)\n",
        "classifier.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "classifier.fit(X_train,y_train,verbose=1,validation_split=0.2,epochs=50,batch_size=20)\n",
        "score = classifier.evaluate(X_test,y_test)\n",
        "print(\"Score: \")\n",
        "print(score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "320/320 [==============================] - 1s 2ms/step - loss: 0.6604 - accuracy: 0.7956 - val_loss: 0.6104 - val_accuracy: 0.7969\n",
            "Epoch 2/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.7958 - val_loss: 0.5551 - val_accuracy: 0.7969\n",
            "Epoch 3/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5415 - accuracy: 0.7958 - val_loss: 0.5296 - val_accuracy: 0.7969\n",
            "Epoch 4/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5243 - accuracy: 0.7958 - val_loss: 0.5183 - val_accuracy: 0.7969\n",
            "Epoch 5/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5162 - accuracy: 0.7958 - val_loss: 0.5124 - val_accuracy: 0.7969\n",
            "Epoch 6/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7958 - val_loss: 0.5091 - val_accuracy: 0.7969\n",
            "Epoch 7/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.7958 - val_loss: 0.5073 - val_accuracy: 0.7969\n",
            "Epoch 8/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5080 - accuracy: 0.7958 - val_loss: 0.5062 - val_accuracy: 0.7969\n",
            "Epoch 9/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.7958 - val_loss: 0.5056 - val_accuracy: 0.7969\n",
            "Epoch 10/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.7958 - val_loss: 0.5053 - val_accuracy: 0.7969\n",
            "Epoch 11/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7958 - val_loss: 0.5051 - val_accuracy: 0.7969\n",
            "Epoch 12/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7958 - val_loss: 0.5049 - val_accuracy: 0.7969\n",
            "Epoch 13/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7958 - val_loss: 0.5049 - val_accuracy: 0.7969\n",
            "Epoch 14/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7958 - val_loss: 0.5048 - val_accuracy: 0.7969\n",
            "Epoch 15/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7958 - val_loss: 0.5048 - val_accuracy: 0.7969\n",
            "Epoch 16/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7958 - val_loss: 0.5048 - val_accuracy: 0.7969\n",
            "Epoch 17/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7958 - val_loss: 0.5048 - val_accuracy: 0.7969\n",
            "Epoch 18/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7958 - val_loss: 0.5048 - val_accuracy: 0.7969\n",
            "Epoch 19/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 20/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 21/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 22/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 23/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 24/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 25/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 26/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 27/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 28/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 29/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 30/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 31/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 32/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 33/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 34/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 35/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 36/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 37/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 38/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 39/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 40/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 41/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 42/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 43/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 44/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 45/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 46/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 47/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 48/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 49/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "Epoch 50/50\n",
            "320/320 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7958 - val_loss: 0.5047 - val_accuracy: 0.7969\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.7975\n",
            "Score: \n",
            "0.7975000143051147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awN4JfHQ3XT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}